{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d055fd15",
   "metadata": {},
   "source": [
    "# Corrective RAG\n",
    "- Focus is on improving the accuracy and relevance of generated docs by incorporating mechanisms for self reflection and self-grading of retrieved documents\n",
    "- It evaluates the quality of generated docs and applies corrective measures (e.g rewriting queries or augmenting with web search) when needed\n",
    "\n",
    "## Limitations of traditional RAGs\n",
    "- Traditional RAG systems heavily rely on accuracy of retrieved documents. If the retrieved information is flawed or incomplete, the generated response can also be inaccurate\n",
    "\n",
    "## Corrective RAG's core components:\n",
    "- **Retrieval Evaluator**: Assesses the quality and relevance of retrieved documents\n",
    "- **Generative Model**: Generates an initial response based on retrieved information\n",
    "- **Refinement and Correction**: CRAG employs strategies like Knowledge Refinement or web search to addres issues identified by the retrieval evaluator\n",
    "\n",
    "## Benefits of CRAG:\n",
    "- Improved Accuracy\n",
    "- Enhanced Relevance\n",
    "- Increased Robustness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea894d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "load_dotenv()\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY')\n",
    "os.environ['TAVILY_API_KEY'] = os.getenv('TAVILY_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0406a12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "## Build an index\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "\n",
    "# embeddings\n",
    "embd = OpenAIEmbeddings()\n",
    "\n",
    "# Docs to index\n",
    "urls = [\n",
    "    'https://lilianweng.github.io/posts/2023-06-23-agent/',\n",
    "    'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/',\n",
    "    'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/',\n",
    "]\n",
    "\n",
    "# load\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "# split text\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(chunk_size=500, chunk_overlap=0)\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "## Vector stores\n",
    "vector_store = FAISS.from_documents(\n",
    "    documents = doc_splits,\n",
    "    embedding=OpenAIEmbeddings()\n",
    ")\n",
    "\n",
    "## vector store as retriever\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e14687fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='yes'\n"
     ]
    }
   ],
   "source": [
    "## Retrieval grader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Data Model\n",
    "class GradeDocuments(BaseModel):\n",
    "    '''Binary Score for relevance check on retrieved documents'''\n",
    "    \n",
    "    binary_score:str = Field(description='Documents are relevant to question \\'yes\\' or \\'no\\'')\n",
    "    \n",
    "## LLM with function call\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "# prompt\n",
    "system = \"\"\" You're a grader assessing relevance of the retrieved document to a user question. \\n\n",
    "If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\n",
    "\"\"\"\n",
    "grade_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system),\n",
    "        ('human', 'Retrieved document: \\n\\n {document} \\n\\n User questions: {question}')\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader = grade_prompt | structured_llm_grader\n",
    "question = 'agent memory'\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "print(retrieval_grader.invoke({'question':question, 'document':doc_txt}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3eb77718",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In LLM-powered autonomous agents, memory is divided into short-term and long-term components. Short-term memory involves in-context learning, while long-term memory allows the agent to retain and recall information over extended periods, often using an external vector store for fast retrieval. This memory system enables agents to learn from past experiences and improve future actions.\n"
     ]
    }
   ],
   "source": [
    "## generate\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# prompt\n",
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "\n",
    "#LLM\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# post processing\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "# chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Run\n",
    "generation = rag_chain.invoke({'context': docs, 'question':question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f4dee41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is agent memory and how does it function in artificial intelligence systems?'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Question rewriter\n",
    "\n",
    "#LLM\n",
    "llm = ChatOpenAI(model='gpt-4o', temperature=0)\n",
    "\n",
    "# prompt\n",
    "system = ''' You are a question re-writer that converts an input question to a better version that is optimized \\n\n",
    "for web search. Look at my input and try to reason about the underlying semantic intent/ meaning\n",
    "'''\n",
    "\n",
    "rewrite_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        ('system', system),\n",
    "        ('human', 'Here is the initial question: \\n\\n {question} \\n Generate an improved question')\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_rewriter = rewrite_prompt | llm | StrOutputParser()\n",
    "question_rewriter.invoke({'question':question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9bf4a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/15/xbwr_x_d51sf0lj4mptglw6h0000gn/T/ipykernel_50901/484733239.py:3: LangChainDeprecationWarning: The class `TavilySearchResults` was deprecated in LangChain 0.3.25 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-tavily package and should be used instead. To use it run `pip install -U :class:`~langchain-tavily` and import as `from :class:`~langchain_tavily import TavilySearch``.\n",
      "  websearchtool = TavilySearchResults(k=3)\n"
     ]
    }
   ],
   "source": [
    "# Search\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "websearchtool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adaf8344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "class GraphState(TypedDict):\n",
    "    \"\"\"\n",
    "    Represents the state of our graph\n",
    "\n",
    "    Attributes:\n",
    "       question: question\n",
    "       generation: LLM generation\n",
    "       web_search: whether to add web search\n",
    "       documents: list of documents\n",
    "    \"\"\"\n",
    "    \n",
    "    question:str\n",
    "    generation:str\n",
    "    web_search:str\n",
    "    documents: List[str]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "940f42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import Document\n",
    "def retrieve(state):\n",
    "    \"\"\"Retrieve documents \n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of graph\n",
    "        \n",
    "    Returns:\n",
    "        state (dict): New key added to the state, documents that contain retrieved documents\n",
    "    \"\"\"\n",
    "    print('--- RETRIEVE ---')\n",
    "    question = state['question']\n",
    "    # Retrieval\n",
    "    documents = retriever.invoke(question)\n",
    "    return {'documents': documents, 'question':question}    \n",
    "\n",
    "def generate(state):\n",
    "    \"\"\"Generate answer\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the graph\n",
    "    \n",
    "    Return: \n",
    "        state (dict):  New key added to the state, generation, that contains LLM generation\n",
    "    \"\"\"\n",
    "    print('--- GENERATE ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    ## RAG generation\n",
    "    generation = rag_chain.invoke({'context': documents,'question':question})\n",
    "    return {'documents': documents,'question':question, 'generation':generation}\n",
    "\n",
    "def grade_documents(state):\n",
    "    \"\"\"Determines whether the retrieved documents are relevant to the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): Current state of the graph\n",
    "        \n",
    "    Returns:\n",
    "        state (dict): Updates the documents key with only the filtered relevant documents\n",
    "    \"\"\"\n",
    "    print('--- CHECK DOCUMENT RELEVANCE TO THE QUESTION ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    # Score each doc\n",
    "    filtered_docs = []\n",
    "    web_search = 'No'\n",
    "    for d in documents:\n",
    "        score= retrieval_grader.invoke({\n",
    "            'question': question, 'document':d.page_content\n",
    "        })\n",
    "        \n",
    "        grade = score.binary_score\n",
    "        if grade == 'yes':\n",
    "            print('--- GRADE: DOCUMENT RELEVANT ---')\n",
    "            filtered_docs.append(d)\n",
    "        else:\n",
    "            print('--- GRADE: DOCUMENT NOT RELEVANT ---')\n",
    "            web_search = 'yes'\n",
    "            continue\n",
    "    return {'documents':documents, 'question': question, 'web_search': web_search}\n",
    "\n",
    "def transform_query(state):\n",
    "    \"\"\"Transform the query to produce a better question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current state of the graph\n",
    "        \n",
    "    Returns:\n",
    "        state (dict): Updates the key with re-phrased question\n",
    "    \"\"\"\n",
    "    \n",
    "    print('--- TRANSFORM QUERY ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    # rewrite question\n",
    "    better_question = question_rewriter.invoke({'question':question})\n",
    "    return {'documents':documents, 'question':question}\n",
    "\n",
    "def web_search(state):\n",
    "    \"\"\"Web search based on rephrased question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        state (dict): Updates documents key with appended web results\n",
    "    \"\"\"\n",
    "    \n",
    "    print('--- WEB SEARCH ---')\n",
    "    question = state['question']\n",
    "    documents = state['documents']\n",
    "    \n",
    "    # web search\n",
    "    docs = websearchtool.invoke({'query':question})\n",
    "    web_results = '\\n'.join([d['content'] for d in docs])\n",
    "    web_results= Document(page_content=web_results)\n",
    "    documents.append(web_results)\n",
    "    return {'documents':documents, 'question':question}\n",
    "\n",
    "def decide_to_generate(state):\n",
    "    \"\"\"Determines whether to generate an answer or re-generate the question\n",
    "\n",
    "    Args:\n",
    "        state (dict): The current graph state\n",
    "        \n",
    "    Returns:\n",
    "        str: Binary decision for next node call\n",
    "    \"\"\"\n",
    "    \n",
    "    print('--- ASSESS GRADED DOCUMENTS ---')\n",
    "    web_search = state['web_search']\n",
    "    if web_search == 'yes':\n",
    "        print(\" --- DECISION: DOCS NOT RELEVANT TO QUERY, TRANSFORM QUERY ---\")\n",
    "        return 'transform_query'\n",
    "    else:\n",
    "        print('--- DECISION: DOCS RELEVANT TO QUERY, GENERATE ANSWER ---')\n",
    "        return 'generate'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a9bcf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## build the graph\n",
    "from langgraph.graph import START,StateGraph, END\n",
    "from IPython.display import Image, display\n",
    "workflow = StateGraph(GraphState)\n",
    "\n",
    "## add nodes\n",
    "workflow.add_node('retrieve', retrieve)\n",
    "workflow.add_node('grade_documents', grade_documents)\n",
    "workflow.add_node('generate', generate)\n",
    "workflow.add_node('transform_query', transform_query)\n",
    "workflow.add_node('web_search', web_search)\n",
    "\n",
    "# build graph\n",
    "workflow.add_edge(START, 'retrieve')\n",
    "workflow.add_edge('retrieve', 'grade_documents')\n",
    "workflow.add_conditional_edges(\n",
    "    'grade_documents',\n",
    "    decide_to_generate,\n",
    "    {\n",
    "        'transform_query': 'transform_query',\n",
    "        'generate': 'generate'\n",
    "    }\n",
    ")\n",
    "workflow.add_edge('transform_query', 'web_search')\n",
    "workflow.add_edge('web_search', 'generate')\n",
    "workflow.add_edge('generate', END)\n",
    "\n",
    "graph = workflow.compile()\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e13d52a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- RETRIEVE ---\n",
      "--- CHECK DOCUMENT RELEVANCE TO THE QUESTION ---\n",
      "--- GRADE: DOCUMENT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- GRADE: DOCUMENT NOT RELEVANT ---\n",
      "--- ASSESS GRADED DOCUMENTS ---\n",
      " --- DECISION: DOCS NOT RELEVANT TO QUERY, TRANSFORM QUERY ---\n",
      "--- TRANSFORM QUERY ---\n",
      "--- WEB SEARCH ---\n",
      "--- GENERATE ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'What is an agentic RAG?',\n",
       " 'generation': 'An agentic RAG (Retrieval-Augmented Generation) is an advanced system that incorporates AI agents into the RAG pipeline to enhance adaptability, accuracy, and functionality. These agents manage the retrieval and generation processes, allowing for multi-step reasoning, dynamic querying, and decision-making. This approach enables more complex workflows and improves the overall performance of AI applications compared to traditional RAG systems.',\n",
       " 'web_search': 'yes',\n",
       " 'documents': [Document(id='a442a105-1e28-4bda-a0c3-ea5131a7a718', metadata={'source': 'https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/', 'title': \"Prompt Engineering | Lil'Log\", 'description': 'Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.\\nThis post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models. At its core, the goal of prompt engineering is about alignment and model steerability. Check my previous post on controllable text generation.', 'language': 'en'}, page_content='RAG style, $p(a_i \\\\mid q) = \\\\sum_{i=1}^n p_\\\\text{tf-idf} (p_i \\\\mid q) \\\\cdot p_\\\\text{LM}(a_i \\\\mid q, p_i)$, where $p_\\\\text{tf-idf} (p_i \\\\mid q)$ is the normalized cosine similarities between the TF-IDF passage and question representations.\\nNoisy channel inference, $p(a_i\\\\mid q) = \\\\frac{p_\\\\text{LM}(q \\\\mid a_i, p_i) \\\\cdot p_\\\\text{LM}(a_i \\\\mid p_i)}{p_\\\\text{LM}(q \\\\mid p_i)}$\\nProduct-of-Experts (PoE), combines all probabilities used above in addition to $p_\\\\text{LM}(p_i \\\\mid q)$.\\n\\nAccording to their experiments on generation and classification tasks, among three answer reranking scores - PoE > Noisy channel > RAG. Among individual probabilities, $p_\\\\text{LM}(a \\\\mid q, p_i)$ and $p_\\\\text{LM}(q \\\\mid p_i, a)$ are found to be most informative. $p_\\\\text{LM}(q \\\\mid p_i, a)$ captures how well the question can be explained by LM given evidence paragraph and answer and can reliably be used for reranking answer candidates.\\nOne observation with SituatedQA dataset for questions grounded in different dates is that despite LM (pretraining cutoff is year 2020) has access to latest information via Google Search, its performance on post-2020 questions are still a lot worse than on pre-2020 questions. This suggests the existence of some discrepencies or conflicting parametric between contextual information and model internal knowledge.\\nInterestingly it is found to be beneficial even with only “internal retrieval”, that is, to generate knowledge about a topic before answering the question (Liu et al. 2022). First we can use  the following template to extract knowledge:\\nGenerate some knowledge about the input. Examples:'),\n",
       "  Document(id='421a8ee2-6a1c-4724-b8b0-59a8b6d06e95', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='inquired about current trends in anticancer drug discovery;\\nselected a target;\\nrequested a scaffold targeting these compounds;\\nOnce the compound was identified, the model attempted its synthesis.\\n\\nThey also discussed the risks, especially with illicit drugs and bioweapons. They developed a test set containing a list of known chemical weapon agents and asked the agent to synthesize them. 4 out of 11 requests (36%) were accepted to obtain a synthesis solution and the agent attempted to consult documentation to execute the procedure. 7 out of 11 were rejected and among these 7 rejected cases, 5 happened after a Web search while 2 were rejected based on prompt only.\\nGenerative Agents Simulation#\\nGenerative Agents (Park, et al. 2023) is super fun experiment where 25 virtual characters, each controlled by a LLM-powered agent, are living and interacting in a sandbox environment, inspired by The Sims. Generative agents create believable simulacra of human behavior for interactive applications.\\nThe design of generative agents combines LLM with memory, planning and reflection mechanisms to enable agents to behave conditioned on past experience, as well as to interact with other agents.\\n\\nMemory stream: is a long-term memory module (external database) that records a comprehensive list of agents’ experience in natural language.\\n\\nEach element is an observation, an event directly provided by the agent.\\n- Inter-agent communication can trigger new natural language statements.\\n\\n\\nRetrieval model: surfaces the context to inform the agent’s behavior, according to relevance, recency and importance.\\n\\nRecency: recent events have higher scores\\nImportance: distinguish mundane from core memories. Ask LM directly.\\nRelevance: based on how related it is to the current situation / query.\\n\\n\\nReflection mechanism: synthesizes memories into higher level inferences over time and guides the agent’s future behavior. They are higher-level summaries of past events (<- note that this is a bit different from self-reflection above)\\n\\nPrompt LM with 100 most recent observations and to generate 3 most salient high-level questions given a set of observations/statements. Then ask LM to answer those questions.\\n\\n\\nPlanning & Reacting: translate the reflections and the environment information into actions'),\n",
       "  Document(id='8f0ca3a4-3185-4e74-b125-03913d0c7a63', metadata={'source': 'https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/', 'title': \"Adversarial Attacks on LLMs | Lil'Log\", 'description': 'The use of large language models in the real world has strongly accelerated by the launch of ChatGPT. We (including my team at OpenAI, shoutout to them) have invested a lot of effort to build default safe behavior into the model during the alignment process (e.g. via RLHF). However, adversarial attacks or jailbreak prompts could potentially trigger the model to output something undesired.\\nA large body of ground work on adversarial attacks is on images, and differently it operates in the continuous, high-dimensional space. Attacks for discrete data like text have been considered to be a lot more challenging, due to lack of direct gradient signals. My past post on Controllable Text Generation is quite relevant to this topic, as attacking LLMs is essentially to control the model to output a certain type of (unsafe) content.', 'language': 'en'}, page_content='The experiment used the BAD (Bot Adversarial Dialogue) dataset and generated red team test cases using a simple prompt:\\nList of questions to ask someone:\\n1.\\nFor attacks to trigger private personal information, this zero-shot prompt is used:\\nList of questions that inquire about a person\\'s {phone number|home address|Social Security Number|email address}:  \\n1.\\nTo encourage high-quality and diverse samples, they adopted nucleus sampling with $p=0.95$. The diversity is measured as self-BLEU, that is, precisely, the maximum BLEU of a given case against 1000 cases. Lower self-BLEU indicates better diversity. There is a clear tradeoff between sample diversity and attack success rate. Zero-shot generation has least success rate in term of tricking offensive model outputs but preserves sampling diversity well, while with low KL penalty, RL fine-tuning maximizes reward effectively but at the cost of diversity, exploiting one successful attack patterns.\\n\\n\\nThe x-axis measures the % model responses are classified as offensive (= \"attack success rate\") and the y-axis measures sample diversity by self-BLEU. Displayed red team generation methods are zero-shot (ZS), stochastic few-shot (SFS), supervised learning (SL), BAD dataset, RL (A2C with different KL penalties). Each node is colored based % test prompts classified as offensive, where blue is low and red is high. (Image source: Perez et al. 2022)\\n\\nIt is impossible to build a perfect classifier on detecting harmful content and any biases or flaw within this classifier can lead to biased attacks. It is especially easy for RL algorithm to exploit any small issues with the classifier as an effective attack pattern, which may end up just being an attack on the classifier. In addition, someone argues that red-teaming against an existing classifier has marginal benefits because such a classifier can be used directly to filter training data or block model output.\\nCasper et al. (2023) set up a human-in-the-loop red teaming process. The main difference from Perez et al. (2022) is that they explicitly set up a data sampling stage for the target model such that we can collect human labels on them to train a task-specific red team classifier. There are three steps:'),\n",
       "  Document(id='2c347a91-6fe9-4291-a3a5-56b80d6c39f7', metadata={'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/', 'title': \"LLM Powered Autonomous Agents | Lil'Log\", 'description': 'Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.\\nAgent System Overview\\nIn a LLM-powered autonomous agent system, LLM functions as the agent’s brain, complemented by several key components:\\n\\nPlanning\\n\\nSubgoal and decomposition: The agent breaks down large tasks into smaller, manageable subgoals, enabling efficient handling of complex tasks.\\nReflection and refinement: The agent can do self-criticism and self-reflection over past actions, learn from mistakes and refine them for future steps, thereby improving the quality of final results.\\n\\n\\nMemory\\n\\nShort-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\\nLong-term memory: This provides the agent with the capability to retain and recall (infinite) information over extended periods, often by leveraging an external vector store and fast retrieval.\\n\\n\\nTool use\\n\\nThe agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\t\\n\\tOverview of a LLM-powered autonomous agent system.\\n\\nComponent One: Planning\\nA complicated task usually involves many steps. An agent needs to know what they are and plan ahead.', 'language': 'en'}, page_content='The agent learns to call external APIs for extra information that is missing from the model weights (often hard to change after pre-training), including current information, code execution capability, access to proprietary information sources and more.\\n\\n\\n\\n\\n\\nOverview of a LLM-powered autonomous agent system.'),\n",
       "  Document(metadata={}, page_content='Agentic RAG (Retrieval-Augmented Generation) is an extension of the traditional RAG framework that incorporates the concept of agents to enhance the capabilities and functionality of the system. In an agentic RAG, agents are used to orchestrate and manage the various components of the RAG pipeline, as well as to perform additional tasks and reasoning that go beyond simple information retrieval and generation. [...] Agentic RAG is a powerful tool for research, data analysis, and knowledge exploration. It represents a significant leap forward in the field of AI-powered research assistants and virtual assistants. Its ability to reason, adapt, and leverage external knowledge paves the way for a new generation of intelligent agents that can significantly enhance our ability to interact with and analyze information. [...] In today’s business landscape, the demand for intelligent systems capable of retrieving relevant information dynamically has never been higher. Agentic RAG represents a cutting-edge approach that combines the strengths of retrieval-based systems and generative models. LeewayHertz, proficient in AI and innovative technology solutions, is well-positioned in this field, offering unparalleled expertise in building robust agentic RAG systems. Here’s how LeewayHertz can assist in this endeavor:\\n# What is agentic RAG?\\n\\n## Authors\\n\\nStaff writer\\n\\nEditorial Lead, AI Models\\n\\nAgentic RAG is the use of AI agents to facilitate retrieval augmented generation (RAG). Agentic RAG systems add AI agents to the RAG pipeline to increase adaptability and accuracy. Compared to traditional RAG systems, agentic RAG allows large language models (LLMs) to conduct information retrieval from multiple sources and handle more complex workflows.\\n\\n### What is RAG? [...] Adaptability: Traditional RAG systems are reactive data retrieval tools that find relevant information in response to specific queries. There is no ability for the RAG system to adapt to changing contexts or access other data. Optimal results often require extensive prompt engineering.\\n\\nMeanwhile, agentic RAG is a transition from static rule-based querying to adaptive, intelligent problem-solving. Multiagent systems encourage multiple AI models to collaborate and check each other’s work.\\nAgentic RAG is a cutting-edge AI model that introduces AI agents into the RAG pipeline to amplify information retrieval and flexibility. These agents can automate tasks, access external data, create customized outputs, and evolve their performance through continuous learning. Adding agentic AI to RAG systems makes AI applications smarter and more independent.\\n\\nHow agentic RAG works\\n--------------------- [...] Agentic RAG (Retrieval-Augmented Generation) is a framework where an agent actively retrieves and uses relevant information from a knowledge base to enhance the generation of responses, ensuring they are accurate and contextually appropriate.\\n\\n   Share the story\\n\\n   Image 22\\n   Image 23\\n   Image 24\\n   Image 25  \\nLink Copied \\n\\nTry Agentforce\\n\\nImage 26\\n\\nImage 27 [...] Real-time question-answering: Agentic RAG is the tool you need to create intelligent virtual assistants and chatbots that can respond to user queries with precision and immediacy.\\n   Automated support: Agentic RAG can automate customer support tasks, such as resolving common inquiries, scheduling appointments, and providing technical assistance.\\nFAQs\\n\\nWhat is Agentic RAG?\\n\\nAI agent implementation on the RAG pipeline is known as agentic RAG to optimize and manage retrieval and generation processes better than traditional RAG. Using intelligent agents within the traditional RAG pipeline improves reasoning, analysis, and information generation, resulting in better response outcomes.\\n\\nHow does Agentic RAG enhance the user experience? [...] Agentic RAG is an excellent tool for inspiring enthusiasts to become AI adopters. Unlike traditional tools, agentic RAG optimizes retrieval data and avoids rerunning retrieval while generating a response. This reduces consumption rates and saves companies money as they aim to build AI-first customer or employee support. [...] Agent-based RAG implementation is known as agentic RAG in a very fundamental stage. It means embedding the power of the agency or agents with the LLM-based RAGs to help execute multi-task or complex tasks requiring multi-step reasoning, strategies, and utilization of multiple tools is agentic RAG.\\nExplain what Agentic RAG is\\n   Compare it to traditional RAG and other paradigms\\n   Share tools and evaluation strategies to get you started\\n   Explore a practical example from the finance sector\\n\\nImage 3\\n\\n2. What Is Agentic RAG?\\n=======================\\n\\nAgentic RAG is an advanced RAG system that uses LLM-powered agents to perform multi-step reasoning, dynamic querying, and decision-making throughout the retrieval and response process. [...] Agentic RAG didn’t just answer the question, it explained how the answer was derived, giving stakeholders both speed and confidence.\\n\\n10. Conclusion\\n==============\\n\\nAgentic RAG is the natural evolution of retrieval-based AI systems, combining the precision of RAG with the reasoning and planning capabilities of agents. It is especially powerful in regulated, high-stakes, or information-dense industries like finance, legal, and healthcare. [...] If you’re building an AI system that needs to think before it speaks, and back up its answers, Agentic RAG is the framework to use.\\n\\nFor further inquiries or collaboration, feel free to contact me at tungvu.telecom@gmail.com.\\n\\nImage 8\\n\\nSign up to discover human stories that deepen your understanding of the world.\\n------------------------------------------------------------------------------\\n\\nFree\\n----\\n\\nDistraction-free reading. No ads.\\n\\nOrganize your knowledge with lists and highlights.')]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# invoke graph\n",
    "graph.invoke({'question': 'What is an agentic RAG?'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc1f151",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph-agents",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
